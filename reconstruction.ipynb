{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch                                       # pytorch本体\n",
    "import torch.nn as nn                              # ニューラルネットを構成する際の基本的なモジュールが入っている\n",
    "import torch.optim as optim                        # ニューラルネットを最適化するためのoptimizerが入っている\n",
    "from torchvision import transforms as transforms   # 画像前処理のために使用\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter  # 学習ログのグラフ化のために使用\n",
    "\n",
    "import logging                                     # ニューラルネットの学習ログをとるために使用\n",
    "logger = logging.getLogger(__name__)               # ロガーの初期化\n",
    "\n",
    "from tqdm import tqdm,trange                              # プログレスバーを出すために使用\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image                              # 画像を取り扱うために使用\n",
    "import matplotlib.pyplot as plt                    # 画像のサンプル表示のために使用\n",
    "import cv2\n",
    "import cupy as cp\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataのロードとdataloarderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([557, 371, 360])\n"
     ]
    }
   ],
   "source": [
    "#ファイルのロード\n",
    "sinogram_path=\"sinogram/sinogram_2410.npy\"\n",
    "sinogram=np.load(sinogram_path,allow_pickle=True)\n",
    "sinogram_tensor=torch.tensor(sinogram).to(device)#tensor型に直す\n",
    "print(sinogram_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daaloarderの作成\n",
    "batch_size=600 #ミニバッチのサイズを指定\n",
    "target_dataloarder=torch.utils.data.DataLoader(sinogram_tensor.to(device),batch_size=batch_size,shuffle=False)#シャッフルは切っておく\n",
    "predict_dataloarder=torch.utils.data.DataLoader(torch.zeros_like(sinogram_tensor),batch_size=batch_size,shuffle=False)#シャッフルは切っておく\n",
    "\n",
    "dataloarders_dict={\"target\":target_dataloarder,\"predict\":predict_dataloarder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルとかの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル\n",
    "class ART(nn.Module):\n",
    "    def __init__(self,sinogram):\n",
    "        super(ART, self).__init__()  # これを追加\n",
    "        self.device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.sinogram=sinogram #[N,Size,Angle]\n",
    "        from torch_radon import Radon,Radon\n",
    "        #ラドン変換の関数の初期化\n",
    "        self.radon_func=Radon(resolution=371, angles=sinogram_tensor[0,0,:], det_count=- 1, det_spacing=1.0, clip_to_circle=False)\n",
    "    \n",
    "    #ラドン変換の関数の定義\n",
    "    def A(self,tomography):\n",
    "        return self.radon_func.forward(tomography)\n",
    "    def AT(self,sinogram):\n",
    "        return self.radon_func.backprojection(sinogram)\n",
    "    \n",
    "    #損失関数の定義\n",
    "    def loss(self,predict,target):\n",
    "        ATA=self.AT(self.A(torch.ones_like(target)))\n",
    "        return torch.divide(self.AT(target - self.A(predict)), ATA)\n",
    "    \n",
    "    def forward(self,target,predict):\n",
    "        loss=self.loss(predict,target)\n",
    "        predict=predict+loss*0.1\n",
    "        return predict,loss\n",
    "\n",
    "# ループの関数\n",
    "def trainer(model, dataloaders_dict, eps=1e-7):\n",
    "    predict_dataloader = dataloaders_dict[\"predict\"]\n",
    "    target_dataloader = dataloaders_dict[\"target\"]\n",
    "\n",
    "    ave_loss = float(\"inf\")\n",
    "    \n",
    "    predicted_list=[]\n",
    "\n",
    "    for predict_batch, target_batch in zip(predict_dataloader, target_dataloader):\n",
    "        predict_batch = predict_batch.to(model.device)\n",
    "        target_batch = target_batch.to(model.device)\n",
    "        iter=0\n",
    "        while ave_loss > eps:\n",
    "            predict_output, loss = model(target_batch, predict_batch)\n",
    "            predict_batch = predict_output  # 予測を更新\n",
    "            ave_loss = torch.mean(torch.abs(loss)).item()\n",
    "            print(f'Iteration: {iter}, Loss: {ave_loss}') \n",
    "            iter+=1\n",
    "        predicted_list.append(np.array(predict_batch.cpu()))\n",
    "    return np.array(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input images must be square, got shape (371, 360).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39mART(sinogram)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m predicted_array\u001b[38;5;241m=\u001b[39m\u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataloarders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_array\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(model, dataloaders_dict, eps)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m ave_loss \u001b[38;5;241m>\u001b[39m eps:\n\u001b[0;32m---> 41\u001b[0m     predict_output, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     predict_batch \u001b[38;5;241m=\u001b[39m predict_output  \u001b[38;5;66;03m# 予測を更新\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     ave_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(loss))\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mART.forward\u001b[0;34m(self, target, predict)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,target,predict):\n\u001b[0;32m---> 23\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     predict\u001b[38;5;241m=\u001b[39mpredict\u001b[38;5;241m+\u001b[39mloss\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict,loss\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mART.loss\u001b[0;34m(self, predict, target)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m,predict,target):\n\u001b[0;32m---> 19\u001b[0m     ATA\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAT(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdivide(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAT(target \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA(predict)), ATA)\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mART.A\u001b[0;34m(self, tomography)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mA\u001b[39m(\u001b[38;5;28mself\u001b[39m,tomography):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradon_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtomography\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch_radon-1.0.0-py3.11-linux-x86_64.egg/torch_radon/utils.py:30\u001b[0m, in \u001b[0;36mnormalize_shape.<locals>.wrap.<locals>.wrapped\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     28\u001b[0m     x, old_shape \u001b[38;5;241m=\u001b[39m _normalize_shape(x, d)\n\u001b[0;32m---> 30\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unnormalize_shape(y, old_shape)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch_radon-1.0.0-py3.11-linux-x86_64.egg/torch_radon/__init__.py:63\u001b[0m, in \u001b[0;36mBaseRadon.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;129m@normalize_shape\u001b[39m(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Radon forward projection.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    :param x: PyTorch GPU tensor with shape :math:`(d_1, \\dots, d_n, r, r)` where :math:`r` is the :attr:`resolution`\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        given to the constructor of this class.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    :returns: PyTorch GPU tensor containing sinograms. Has shape :math:`(d_1, \\dots, d_n, len(angles), det\\_count)`.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_parameters_to_device(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RadonForward\u001b[38;5;241m.\u001b[39mapply(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangles, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtex_cache, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrays_cfg)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/torch_radon-1.0.0-py3.11-linux-x86_64.egg/torch_radon/__init__.py:47\u001b[0m, in \u001b[0;36mBaseRadon._check_input\u001b[0;34m(self, x, square)\u001b[0m\n\u001b[1;32m     44\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m square:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput images must be square, got shape (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size must be multiple of 4 when using half precision. Got batch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input images must be square, got shape (371, 360)."
     ]
    }
   ],
   "source": [
    "model=ART(sinogram).to(device)\n",
    "predicted_array=trainer(model,dataloarders_dict,eps=1e-10)\n",
    "print(predicted_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f704f9c62d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predicted_array[0,:,180,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
